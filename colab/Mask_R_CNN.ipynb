{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSZtjuigz4_H"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzQhQ9Yo8qBD"
      },
      "source": [
        "### Check assigned GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OBr7yC0ue3Q",
        "outputId": "bff7dccd-f5b7-4bf7-f675-f3a1e6387d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Mar 15 00:50:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyXFXS5V8yx0"
      },
      "source": [
        "### Check assigned memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rouTdwNn8ore",
        "outputId": "31651b9b-d26f-4357-ca11-4fa67eb7bf98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVQm_jK39JNp"
      },
      "source": [
        "### Download Object Detection API repo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2SoQ0W1Utyw",
        "outputId": "b002149c-bf32-4e1a-9076-c5392a0bb590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'object-detection-api'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (361/361), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 361 (delta 136), reused 317 (delta 92), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (361/361), 1.77 MiB | 25.91 MiB/s, done.\n",
            "Resolving deltas: 100% (136/136), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf object-detection-api && git clone https://github.com/CatchZeng/object-detection-api.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg1JKJsL9PTT"
      },
      "source": [
        "### Install Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnzaf2VcU2_Q",
        "outputId": "c14bd1db-b7a5-4959-e9c5-98a6674582aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "if [ -d \"./models\" ]; then \\\n",
            "    echo 'models downloaded'; \\\n",
            "  else \\\n",
            "        git clone --depth=1 https://github.com/tensorflow/models; \\\n",
            "fi\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3464, done.\u001b[K\n",
            "remote: Counting objects: 100% (3464/3464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2781/2781), done.\u001b[K\n",
            "remote: Total 3464 (delta 1047), reused 1533 (delta 635), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3464/3464), 34.30 MiB | 31.53 MiB/s, done.\n",
            "Resolving deltas: 100% (1047/1047), done.\n",
            "cd models/research && \\\n",
            "protoc object_detection/protos/*.proto --python_out=. && \\\n",
            "cp object_detection/packages/tf2/setup.py . && \\\n",
            "python -m pip install --use-feature=2020-resolver .\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/object-detection-api/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.37.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 46.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 93.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.9 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 43.9 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 49 kB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.55.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.63.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 60.0 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1686356 sha256=1448a6f1a2054d366267322db846013144c2a33708cae9576453c7af47171ada\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nz9h9gd4/wheels/55/6d/7e/5975da03d28bb45fd7c4b4bfc69418bfede139c86923f353a8\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=4771b5f2e6cd441e6243e68cbbbd194db24e190a8f018c1ca9cd395d4f44e364\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=f494aaf3ebf7b02a1adf2ac83105fe7ea3121d57b3a6f5637fac638d6aba3205\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=74cadd494cf3f1e4d3cbd193d777f1c8c8e5a654d6fe020aac823ac5c1235862\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=603115657b85e9328c4d90cfddac2ccd6efe00251ed293e4f11eef494fdd7588\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.2\n",
            "    Uninstalling pymongo-4.0.2:\n",
            "      Successfully uninstalled pymongo-4.0.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.37.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n",
            "cd models/research && \\\n",
            "python object_detection/builders/model_builder_tf2_test.py\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-03-15 00:51:08.351875: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0315 00:51:08.778074 140103119931264 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.08s\n",
            "I0315 00:51:09.064179 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "I0315 00:51:09.636791 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.57s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.42s\n",
            "I0315 00:51:10.061324 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.42s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
            "I0315 00:51:10.356393 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.05s\n",
            "I0315 00:51:12.406299 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0315 00:51:12.407383 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0315 00:51:12.432871 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0315 00:51:12.449033 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0315 00:51:12.466627 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "I0315 00:51:12.574502 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "I0315 00:51:12.682196 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I0315 00:51:12.795893 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I0315 00:51:12.906821 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "I0315 00:51:13.021180 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0315 00:51:13.052961 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0315 00:51:13.251643 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0315 00:51:13.251828 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0315 00:51:13.251908 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0315 00:51:13.255039 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:13.446161 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:13.446356 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:13.507327 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:13.507504 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:13.663952 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:13.664151 140103119931264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0315 00:51:13.815543 140103119931264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0315 00:51:13.815729 140103119931264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0315 00:51:14.059258 140103119931264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0315 00:51:14.059441 140103119931264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0315 00:51:14.301694 140103119931264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0315 00:51:14.301921 140103119931264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0315 00:51:14.624181 140103119931264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0315 00:51:14.624377 140103119931264 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0315 00:51:14.698128 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0315 00:51:14.728123 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:14.782693 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0315 00:51:14.783027 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0315 00:51:14.783196 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0315 00:51:14.785521 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:14.802513 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:14.802652 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:14.926906 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:14.927097 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:15.160156 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:15.160361 140103119931264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0315 00:51:15.394212 140103119931264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0315 00:51:15.394398 140103119931264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0315 00:51:15.705588 140103119931264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0315 00:51:15.705787 140103119931264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0315 00:51:16.018637 140103119931264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0315 00:51:16.018845 140103119931264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0315 00:51:16.420085 140103119931264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0315 00:51:16.420303 140103119931264 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0315 00:51:16.576637 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0315 00:51:16.607808 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:16.675669 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0315 00:51:16.675858 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0315 00:51:16.675933 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0315 00:51:16.677741 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:16.693794 140103119931264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0315 00:51:16.693949 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:16.814449 140103119931264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0315 00:51:16.814642 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:17.049719 140103119931264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0315 00:51:17.049910 140103119931264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0315 00:51:17.285328 140103119931264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0315 00:51:17.285511 140103119931264 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0315 00:51:17.772344 140103119931264 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0315 00:51:17.772542 140103119931264 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0315 00:51:18.085623 140103119931264 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0315 00:51:18.085804 140103119931264 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0315 00:51:18.491978 140103119931264 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0315 00:51:18.492192 140103119931264 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0315 00:51:18.644421 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0315 00:51:18.674261 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:18.742434 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0315 00:51:18.742616 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0315 00:51:18.742734 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0315 00:51:18.744537 140103119931264 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0315 00:51:18.760000 140103119931264 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0315 00:51:18.760132 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:18.884306 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:18.884493 140103119931264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0315 00:51:19.138015 140103119931264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0315 00:51:19.138216 140103119931264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0315 00:51:19.385447 140103119931264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0315 00:51:19.385669 140103119931264 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0315 00:51:19.785814 140103119931264 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0315 00:51:19.786017 140103119931264 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0315 00:51:20.199007 140103119931264 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0315 00:51:20.199246 140103119931264 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0315 00:51:20.672808 140103119931264 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0315 00:51:20.672993 140103119931264 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0315 00:51:20.840147 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0315 00:51:20.868135 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:20.943439 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0315 00:51:20.943619 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0315 00:51:20.943702 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0315 00:51:20.945374 140103119931264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0315 00:51:20.961365 140103119931264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0315 00:51:20.961546 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:21.090976 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:21.091192 140103119931264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0315 00:51:21.406308 140103119931264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0315 00:51:21.406505 140103119931264 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0315 00:51:21.724491 140103119931264 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0315 00:51:21.724687 140103119931264 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0315 00:51:22.191741 140103119931264 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0315 00:51:22.191926 140103119931264 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0315 00:51:22.916442 140103119931264 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0315 00:51:22.916668 140103119931264 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0315 00:51:23.533767 140103119931264 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0315 00:51:23.533952 140103119931264 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0315 00:51:23.681701 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0315 00:51:23.710283 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:23.787576 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0315 00:51:23.787759 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0315 00:51:23.787844 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0315 00:51:23.789467 140103119931264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0315 00:51:23.808241 140103119931264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0315 00:51:23.808381 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:23.995409 140103119931264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0315 00:51:23.995625 140103119931264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0315 00:51:24.428768 140103119931264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0315 00:51:24.428977 140103119931264 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0315 00:51:24.868586 140103119931264 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0315 00:51:24.868803 140103119931264 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0315 00:51:25.453762 140103119931264 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0315 00:51:25.453963 140103119931264 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0315 00:51:26.017294 140103119931264 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0315 00:51:26.017488 140103119931264 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0315 00:51:26.714362 140103119931264 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0315 00:51:26.714555 140103119931264 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0315 00:51:26.947152 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0315 00:51:26.978869 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:27.086459 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0315 00:51:27.086663 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0315 00:51:27.086750 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0315 00:51:27.088713 140103119931264 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0315 00:51:27.105802 140103119931264 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0315 00:51:27.106007 140103119931264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0315 00:51:27.297180 140103119931264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0315 00:51:27.297397 140103119931264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0315 00:51:27.778434 140103119931264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0315 00:51:27.778628 140103119931264 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0315 00:51:28.533026 140103119931264 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0315 00:51:28.533242 140103119931264 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0315 00:51:29.166981 140103119931264 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0315 00:51:29.167175 140103119931264 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0315 00:51:29.814929 140103119931264 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0315 00:51:29.815129 140103119931264 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0315 00:51:30.688665 140103119931264 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0315 00:51:30.688859 140103119931264 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0315 00:51:30.912867 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0315 00:51:30.943912 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0315 00:51:31.048087 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0315 00:51:31.048294 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0315 00:51:31.048371 140103119931264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0315 00:51:31.050087 140103119931264 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0315 00:51:31.065135 140103119931264 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0315 00:51:31.065272 140103119931264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0315 00:51:31.318242 140103119931264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0315 00:51:31.318433 140103119931264 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0315 00:51:31.851568 140103119931264 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0315 00:51:31.851772 140103119931264 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0315 00:51:32.393048 140103119931264 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0315 00:51:32.393258 140103119931264 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0315 00:51:33.174304 140103119931264 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0315 00:51:33.174491 140103119931264 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0315 00:51:34.248744 140103119931264 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0315 00:51:34.248942 140103119931264 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0315 00:51:35.281650 140103119931264 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0315 00:51:35.281861 140103119931264 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0315 00:51:35.599459 140103119931264 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0315 00:51:35.638406 140103119931264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.72s\n",
            "I0315 00:51:35.777492 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0315 00:51:35.784096 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0315 00:51:35.785991 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0315 00:51:35.786497 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0315 00:51:35.788050 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0315 00:51:35.789450 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0315 00:51:35.789904 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0315 00:51:35.790912 140103119931264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 29.805s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "!cd object-detection-api && make install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOAxt-F20j12"
      },
      "source": [
        "\n",
        "### Go to workspace dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvZpWpzD0kZM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/object-detection-api/workspace/test-mask\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMUZNcA69ZH9"
      },
      "source": [
        "### Download pre-trained Mask R-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdF8kl60uvVQ",
        "outputId": "e090273c-f302-4ee2-cdf2-b732f3f6a96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir -p pre-trained-models; \\\n",
            "model=mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8; \\\n",
            "curl -O http://download.tensorflow.org/models/object_detection/tf2/20200711/$model.tar.gz; \\\n",
            "tar zxvf $model.tar.gz; \\\n",
            "mv -f $model ./pre-trained-models/; \\\n",
            "rm -rf $model $model.tar.gz;\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  462M  100  462M    0     0   118M      0  0:00:03  0:00:03 --:--:--  118M\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/checkpoint\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/saved_model.pb\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "!make dl-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pqn_9Kv9gyu"
      },
      "source": [
        "## Train model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-jmxz5kvrfy",
        "outputId": "acef7633-13da-4ec2-cb27-b0124cb7aea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python model_main_tf2.py \\\n",
            "--model_dir=models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8 \\\n",
            "--pipeline_config_path=models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "2022-03-15 00:53:29.008655: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0315 00:53:29.014656 140483420235648 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0315 00:53:29.019054 140483420235648 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0315 00:53:29.019262 140483420235648 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0315 00:53:29.061480 140483420235648 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['annotations/train.record']\n",
            "I0315 00:53:29.072860 140483420235648 dataset_builder.py:163] Reading unweighted datasets: ['annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['annotations/train.record']\n",
            "I0315 00:53:29.073121 140483420235648 dataset_builder.py:80] Reading record datasets for input file: ['annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0315 00:53:29.073235 140483420235648 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0315 00:53:29.073321 140483420235648 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0315 00:53:29.078843 140483420235648 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0315 00:53:29.107729 140483420235648 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0315 00:53:31.225350 140483420235648 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0315 00:53:36.922268 140483420235648 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0315 00:53:39.893279 140483420235648 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 00:53:54.888700 140478250145536 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0315 00:54:00.903032 140478250145536 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0315 00:54:01.416193 140478250145536 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0315 00:54:05.280495 140478250145536 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0315 00:54:09.914013 140478250145536 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.650227 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.651645 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.653575 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.654915 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.656978 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.658237 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.660301 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.661350 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.663558 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0315 00:54:48.664727 140483420235648 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0315 00:54:50.211816 140478275323648 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.405s\n",
            "I0315 00:57:10.471228 140483420235648 model_lib_v2.py:707] Step 100 per-step time 1.405s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.21923682,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.6412294,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 1.5209256,\n",
            " 'Loss/RPNLoss/localization_loss': 0.056536768,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0681395,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 2.5060682,\n",
            " 'learning_rate': 0.0032}\n",
            "I0315 00:57:10.471685 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.21923682,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.6412294,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 1.5209256,\n",
            " 'Loss/RPNLoss/localization_loss': 0.056536768,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0681395,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 2.5060682,\n",
            " 'learning_rate': 0.0032}\n",
            "INFO:tensorflow:Step 200 per-step time 0.588s\n",
            "I0315 00:58:09.071489 140483420235648 model_lib_v2.py:707] Step 200 per-step time 0.588s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18623573,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.2476046,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.4046885,\n",
            " 'Loss/RPNLoss/localization_loss': 0.04474159,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.028450396,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.9117208,\n",
            " 'learning_rate': 0.0064}\n",
            "I0315 00:58:09.071852 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.18623573,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.2476046,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.4046885,\n",
            " 'Loss/RPNLoss/localization_loss': 0.04474159,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.028450396,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.9117208,\n",
            " 'learning_rate': 0.0064}\n",
            "INFO:tensorflow:Step 300 per-step time 0.584s\n",
            "I0315 00:59:07.475342 140483420235648 model_lib_v2.py:707] Step 300 per-step time 0.584s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.118595526,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.12276756,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.2898434,\n",
            " 'Loss/RPNLoss/localization_loss': 0.038896002,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.034031365,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.6041339,\n",
            " 'learning_rate': 0.007997814}\n",
            "I0315 00:59:07.475754 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.118595526,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.12276756,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.2898434,\n",
            " 'Loss/RPNLoss/localization_loss': 0.038896002,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.034031365,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.6041339,\n",
            " 'learning_rate': 0.007997814}\n",
            "INFO:tensorflow:Step 400 per-step time 0.580s\n",
            "I0315 01:00:05.485611 140483420235648 model_lib_v2.py:707] Step 400 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.076890275,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.117803946,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.32228485,\n",
            " 'Loss/RPNLoss/localization_loss': 0.025306702,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.024244074,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.56652987,\n",
            " 'learning_rate': 0.007980332}\n",
            "I0315 01:00:05.485973 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.076890275,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.117803946,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.32228485,\n",
            " 'Loss/RPNLoss/localization_loss': 0.025306702,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.024244074,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.56652987,\n",
            " 'learning_rate': 0.007980332}\n",
            "INFO:tensorflow:Step 500 per-step time 0.580s\n",
            "I0315 01:01:03.529393 140483420235648 model_lib_v2.py:707] Step 500 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0360966,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.02452873,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.18192044,\n",
            " 'Loss/RPNLoss/localization_loss': 0.010895336,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.012581634,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26602274,\n",
            " 'learning_rate': 0.007945445}\n",
            "I0315 01:01:03.529760 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0360966,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.02452873,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.18192044,\n",
            " 'Loss/RPNLoss/localization_loss': 0.010895336,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.012581634,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26602274,\n",
            " 'learning_rate': 0.007945445}\n",
            "INFO:tensorflow:Step 600 per-step time 0.580s\n",
            "I0315 01:02:01.547342 140483420235648 model_lib_v2.py:707] Step 600 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07078271,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06461669,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20704417,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0044974186,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.004910341,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.35185134,\n",
            " 'learning_rate': 0.007893307}\n",
            "I0315 01:02:01.547695 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07078271,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.06461669,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20704417,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0044974186,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.004910341,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.35185134,\n",
            " 'learning_rate': 0.007893307}\n",
            "INFO:tensorflow:Step 700 per-step time 0.581s\n",
            "I0315 01:02:59.677915 140483420235648 model_lib_v2.py:707] Step 700 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.038921762,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.04271553,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.16582705,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0078044636,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0089338245,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26420262,\n",
            " 'learning_rate': 0.007824143}\n",
            "I0315 01:02:59.678295 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.038921762,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.04271553,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.16582705,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0078044636,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0089338245,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26420262,\n",
            " 'learning_rate': 0.007824143}\n",
            "INFO:tensorflow:Step 800 per-step time 0.580s\n",
            "I0315 01:03:57.646055 140483420235648 model_lib_v2.py:707] Step 800 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.07837154,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01958672,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.16433132,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0006726484,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002699627,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26566184,\n",
            " 'learning_rate': 0.007738258}\n",
            "I0315 01:03:57.646413 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.07837154,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01958672,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.16433132,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0006726484,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002699627,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.26566184,\n",
            " 'learning_rate': 0.007738258}\n",
            "INFO:tensorflow:Step 900 per-step time 0.582s\n",
            "I0315 01:04:55.852943 140483420235648 model_lib_v2.py:707] Step 900 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.060344473,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.029295662,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20588169,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005563411,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0044073584,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.30549258,\n",
            " 'learning_rate': 0.007636027}\n",
            "I0315 01:04:55.853316 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.060344473,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.029295662,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20588169,\n",
            " 'Loss/RPNLoss/localization_loss': 0.005563411,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0044073584,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.30549258,\n",
            " 'learning_rate': 0.007636027}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.581s\n",
            "I0315 01:05:53.956127 140483420235648 model_lib_v2.py:707] Step 1000 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.019260349,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01945981,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.17424776,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0016000058,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0046332832,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.2192012,\n",
            " 'learning_rate': 0.007517895}\n",
            "I0315 01:05:53.956570 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.019260349,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01945981,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.17424776,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0016000058,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0046332832,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.2192012,\n",
            " 'learning_rate': 0.007517895}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.618s\n",
            "I0315 01:06:55.758634 140483420235648 model_lib_v2.py:707] Step 1100 per-step time 0.618s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0114032375,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.008133858,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.076451436,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0014924435,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0010384237,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09851939,\n",
            " 'learning_rate': 0.0073843817}\n",
            "I0315 01:06:55.759087 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0114032375,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.008133858,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.076451436,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0014924435,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0010384237,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09851939,\n",
            " 'learning_rate': 0.0073843817}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.580s\n",
            "I0315 01:07:53.804325 140483420235648 model_lib_v2.py:707] Step 1200 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.011536414,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01448002,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.13782366,\n",
            " 'Loss/RPNLoss/localization_loss': 0.006175986,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003787454,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17380352,\n",
            " 'learning_rate': 0.007236068}\n",
            "I0315 01:07:53.804694 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.011536414,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.01448002,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.13782366,\n",
            " 'Loss/RPNLoss/localization_loss': 0.006175986,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.003787454,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17380352,\n",
            " 'learning_rate': 0.007236068}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.581s\n",
            "I0315 01:08:51.924385 140483420235648 model_lib_v2.py:707] Step 1300 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.046717808,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0066647427,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.12360886,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008029609,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00087946426,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17867383,\n",
            " 'learning_rate': 0.007073605}\n",
            "I0315 01:08:51.924759 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.046717808,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0066647427,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.12360886,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008029609,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00087946426,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17867383,\n",
            " 'learning_rate': 0.007073605}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.580s\n",
            "I0315 01:09:49.943808 140483420235648 model_lib_v2.py:707] Step 1400 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.18559353,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.03534594,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20596555,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0019398928,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002262877,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.43110782,\n",
            " 'learning_rate': 0.0068977014}\n",
            "I0315 01:09:49.944196 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.18559353,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.03534594,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.20596555,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0019398928,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.002262877,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.43110782,\n",
            " 'learning_rate': 0.0068977014}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.581s\n",
            "I0315 01:10:48.091923 140483420235648 model_lib_v2.py:707] Step 1500 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.070085265,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.008884448,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1155139,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008110207,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0006906203,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19598526,\n",
            " 'learning_rate': 0.0067091268}\n",
            "I0315 01:10:48.092294 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.070085265,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.008884448,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1155139,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008110207,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0006906203,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.19598526,\n",
            " 'learning_rate': 0.0067091268}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.581s\n",
            "I0315 01:11:46.199762 140483420235648 model_lib_v2.py:707] Step 1600 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.004728986,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.009499493,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1204345,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00064106047,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0004438639,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13574791,\n",
            " 'learning_rate': 0.0065087057}\n",
            "I0315 01:11:46.200159 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.004728986,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.009499493,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1204345,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00064106047,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0004438639,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13574791,\n",
            " 'learning_rate': 0.0065087057}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.581s\n",
            "I0315 01:12:44.310583 140483420235648 model_lib_v2.py:707] Step 1700 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.013296063,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0052703074,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.0974287,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007802104,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00052056665,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.11729585,\n",
            " 'learning_rate': 0.006297315}\n",
            "I0315 01:12:44.310948 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.013296063,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0052703074,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.0974287,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007802104,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00052056665,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.11729585,\n",
            " 'learning_rate': 0.006297315}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.582s\n",
            "I0315 01:13:42.487079 140483420235648 model_lib_v2.py:707] Step 1800 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.041380152,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0056706797,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1205437,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0015527381,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0011411525,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17028841,\n",
            " 'learning_rate': 0.0060758786}\n",
            "I0315 01:13:42.487483 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.041380152,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0056706797,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.1205437,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0015527381,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0011411525,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17028841,\n",
            " 'learning_rate': 0.0060758786}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.579s\n",
            "I0315 01:14:40.422762 140483420235648 model_lib_v2.py:707] Step 1900 per-step time 0.579s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.010829938,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.005434792,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.11428065,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008589502,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0011771398,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13258147,\n",
            " 'learning_rate': 0.0058453646}\n",
            "I0315 01:14:40.423152 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.010829938,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.005434792,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.11428065,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0008589502,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0011771398,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13258147,\n",
            " 'learning_rate': 0.0058453646}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.582s\n",
            "I0315 01:15:38.598499 140483420235648 model_lib_v2.py:707] Step 2000 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.003026067,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0036503451,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.11770213,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0014275648,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.001841574,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12764767,\n",
            " 'learning_rate': 0.005606782}\n",
            "I0315 01:15:38.598880 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.003026067,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0036503451,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.11770213,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0014275648,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.001841574,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.12764767,\n",
            " 'learning_rate': 0.005606782}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.611s\n",
            "I0315 01:16:39.696755 140483420235648 model_lib_v2.py:707] Step 2100 per-step time 0.611s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.11684945,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0034464034,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.057839155,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001793033,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0005104932,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17882481,\n",
            " 'learning_rate': 0.005361173}\n",
            "I0315 01:16:39.697111 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.11684945,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0034464034,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.057839155,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001793033,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0005104932,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.17882481,\n",
            " 'learning_rate': 0.005361173}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.581s\n",
            "I0315 01:17:37.815671 140483420235648 model_lib_v2.py:707] Step 2200 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.009658134,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0032769148,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09810834,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0009027264,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008954754,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.11284159,\n",
            " 'learning_rate': 0.005109612}\n",
            "I0315 01:17:37.816021 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.009658134,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0032769148,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09810834,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0009027264,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008954754,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.11284159,\n",
            " 'learning_rate': 0.005109612}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.581s\n",
            "I0315 01:18:35.910295 140483420235648 model_lib_v2.py:707] Step 2300 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.003651999,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0020668379,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09434337,\n",
            " 'Loss/RPNLoss/localization_loss': 9.568964e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00041325833,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.100571156,\n",
            " 'learning_rate': 0.0048531983}\n",
            "I0315 01:18:35.910668 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.003651999,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0020668379,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09434337,\n",
            " 'Loss/RPNLoss/localization_loss': 9.568964e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00041325833,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.100571156,\n",
            " 'learning_rate': 0.0048531983}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.581s\n",
            "I0315 01:19:33.994387 140483420235648 model_lib_v2.py:707] Step 2400 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.009677942,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0018013552,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08651224,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00049530796,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00023922828,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09872607,\n",
            " 'learning_rate': 0.0045930543}\n",
            "I0315 01:19:33.994757 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.009677942,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0018013552,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08651224,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00049530796,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00023922828,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09872607,\n",
            " 'learning_rate': 0.0045930543}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.581s\n",
            "I0315 01:20:32.100052 140483420235648 model_lib_v2.py:707] Step 2500 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0014868089,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0020066078,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.0939094,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015456289,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00020339194,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09776077,\n",
            " 'learning_rate': 0.0043303175}\n",
            "I0315 01:20:32.100393 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0014868089,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0020066078,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.0939094,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015456289,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00020339194,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09776077,\n",
            " 'learning_rate': 0.0043303175}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.581s\n",
            "I0315 01:21:30.152000 140483420235648 model_lib_v2.py:707] Step 2600 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.022080278,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0021571224,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10816318,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0006317981,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0007123178,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13374469,\n",
            " 'learning_rate': 0.0040661357}\n",
            "I0315 01:21:30.152366 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.022080278,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0021571224,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10816318,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0006317981,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0007123178,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.13374469,\n",
            " 'learning_rate': 0.0040661357}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.580s\n",
            "I0315 01:22:28.109668 140483420235648 model_lib_v2.py:707] Step 2700 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0010967386,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0009833296,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10222258,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007634995,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00055078475,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10561693,\n",
            " 'learning_rate': 0.0038016646}\n",
            "I0315 01:22:28.110030 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0010967386,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0009833296,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10222258,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007634995,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00055078475,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10561693,\n",
            " 'learning_rate': 0.0038016646}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.582s\n",
            "I0315 01:23:26.274035 140483420235648 model_lib_v2.py:707] Step 2800 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00040607632,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0013537052,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.079501286,\n",
            " 'Loss/RPNLoss/localization_loss': 9.233315e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00031913453,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08167254,\n",
            " 'learning_rate': 0.0035380614}\n",
            "I0315 01:23:26.274536 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00040607632,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0013537052,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.079501286,\n",
            " 'Loss/RPNLoss/localization_loss': 9.233315e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00031913453,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08167254,\n",
            " 'learning_rate': 0.0035380614}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.580s\n",
            "I0315 01:24:24.303841 140483420235648 model_lib_v2.py:707] Step 2900 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.001299032,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0015851357,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08001056,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001260314,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00030651691,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08332728,\n",
            " 'learning_rate': 0.003276478}\n",
            "I0315 01:24:24.304192 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.001299032,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0015851357,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08001056,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001260314,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00030651691,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08332728,\n",
            " 'learning_rate': 0.003276478}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.581s\n",
            "I0315 01:25:22.413983 140483420235648 model_lib_v2.py:707] Step 3000 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0011400288,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0008343392,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09053377,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001561803,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0001550095,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.092819326,\n",
            " 'learning_rate': 0.0030180581}\n",
            "I0315 01:25:22.414387 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0011400288,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0008343392,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09053377,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001561803,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0001550095,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.092819326,\n",
            " 'learning_rate': 0.0030180581}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.615s\n",
            "I0315 01:26:23.956308 140483420235648 model_lib_v2.py:707] Step 3100 per-step time 0.615s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0033781931,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0014545333,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10000609,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007732663,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0005134695,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.106125556,\n",
            " 'learning_rate': 0.0027639319}\n",
            "I0315 01:26:23.956688 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0033781931,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0014545333,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10000609,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0007732663,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0005134695,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.106125556,\n",
            " 'learning_rate': 0.0027639319}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.581s\n",
            "I0315 01:27:22.048913 140483420235648 model_lib_v2.py:707] Step 3200 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00064911647,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.001094752,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10408338,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00024449866,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008043322,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10687608,\n",
            " 'learning_rate': 0.0025152112}\n",
            "I0315 01:27:22.049310 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00064911647,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.001094752,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10408338,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00024449866,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0008043322,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10687608,\n",
            " 'learning_rate': 0.0025152112}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.581s\n",
            "I0315 01:28:20.186043 140483420235648 model_lib_v2.py:707] Step 3300 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0020664157,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00095901376,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09136757,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015062978,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00012289925,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094666526,\n",
            " 'learning_rate': 0.0022729828}\n",
            "I0315 01:28:20.186385 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0020664157,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00095901376,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09136757,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015062978,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00012289925,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094666526,\n",
            " 'learning_rate': 0.0022729828}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.581s\n",
            "I0315 01:29:18.328080 140483420235648 model_lib_v2.py:707] Step 3400 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.008956809,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00010892197,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.04560593,\n",
            " 'Loss/RPNLoss/localization_loss': 1.6822165e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00024242079,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.054930903,\n",
            " 'learning_rate': 0.0020383054}\n",
            "I0315 01:29:18.328449 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.008956809,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00010892197,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.04560593,\n",
            " 'Loss/RPNLoss/localization_loss': 1.6822165e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00024242079,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.054930903,\n",
            " 'learning_rate': 0.0020383054}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.581s\n",
            "I0315 01:30:16.401792 140483420235648 model_lib_v2.py:707] Step 3500 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.000593948,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00046761124,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.089919746,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00048343808,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00038385752,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.0918486,\n",
            " 'learning_rate': 0.001812207}\n",
            "I0315 01:30:16.402136 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.000593948,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00046761124,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.089919746,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00048343808,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00038385752,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.0918486,\n",
            " 'learning_rate': 0.001812207}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.581s\n",
            "I0315 01:31:14.462071 140483420235648 model_lib_v2.py:707] Step 3600 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0011504331,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00071111805,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07754685,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00011222038,\n",
            " 'Loss/RPNLoss/objectness_loss': 7.0949594e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.07959157,\n",
            " 'learning_rate': 0.0015956754}\n",
            "I0315 01:31:14.462451 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0011504331,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00071111805,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07754685,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00011222038,\n",
            " 'Loss/RPNLoss/objectness_loss': 7.0949594e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.07959157,\n",
            " 'learning_rate': 0.0015956754}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.581s\n",
            "I0315 01:32:12.575492 140483420235648 model_lib_v2.py:707] Step 3700 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00073459535,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0003628384,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08797077,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00027409146,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00030737615,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08964967,\n",
            " 'learning_rate': 0.0013896568}\n",
            "I0315 01:32:12.575847 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00073459535,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0003628384,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08797077,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00027409146,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00030737615,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08964967,\n",
            " 'learning_rate': 0.0013896568}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.580s\n",
            "I0315 01:33:10.574149 140483420235648 model_lib_v2.py:707] Step 3800 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0008286919,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00060003775,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09237174,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00011788346,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.924078e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094017595,\n",
            " 'learning_rate': 0.0011950522}\n",
            "I0315 01:33:10.574512 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0008286919,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00060003775,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09237174,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00011788346,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.924078e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094017595,\n",
            " 'learning_rate': 0.0011950522}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.580s\n",
            "I0315 01:34:08.588391 140483420235648 model_lib_v2.py:707] Step 3900 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.003462624,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00069257175,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07763775,\n",
            " 'Loss/RPNLoss/localization_loss': 5.7278077e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 7.015514e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08192038,\n",
            " 'learning_rate': 0.0010127138}\n",
            "I0315 01:34:08.588746 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.003462624,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00069257175,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07763775,\n",
            " 'Loss/RPNLoss/localization_loss': 5.7278077e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 7.015514e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08192038,\n",
            " 'learning_rate': 0.0010127138}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.581s\n",
            "I0315 01:35:06.717803 140483420235648 model_lib_v2.py:707] Step 4000 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00017787723,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0003448843,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07914473,\n",
            " 'Loss/RPNLoss/localization_loss': 9.044769e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0002136027,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.079971544,\n",
            " 'learning_rate': 0.00084343774}\n",
            "I0315 01:35:06.718142 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00017787723,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0003448843,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.07914473,\n",
            " 'Loss/RPNLoss/localization_loss': 9.044769e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.0002136027,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.079971544,\n",
            " 'learning_rate': 0.00084343774}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.610s\n",
            "I0315 01:36:07.745493 140483420235648 model_lib_v2.py:707] Step 4100 per-step time 0.610s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0004998441,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00037791763,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08777301,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00013249902,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.29659e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08887624,\n",
            " 'learning_rate': 0.0006879647}\n",
            "I0315 01:36:07.745897 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0004998441,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00037791763,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.08777301,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00013249902,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.29659e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.08887624,\n",
            " 'learning_rate': 0.0006879647}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.581s\n",
            "I0315 01:37:05.881579 140483420235648 model_lib_v2.py:707] Step 4200 per-step time 0.581s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0003298818,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00050876883,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09811184,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00013364456,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.0165384e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.0991743,\n",
            " 'learning_rate': 0.0005469742}\n",
            "I0315 01:37:05.881914 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0003298818,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00050876883,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09811184,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00013364456,\n",
            " 'Loss/RPNLoss/objectness_loss': 9.0165384e-05,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.0991743,\n",
            " 'learning_rate': 0.0005469742}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.583s\n",
            "I0315 01:38:04.195683 140483420235648 model_lib_v2.py:707] Step 4300 per-step time 0.583s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00090906903,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.000680628,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.087792814,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001680642,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014259342,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.089693174,\n",
            " 'learning_rate': 0.00042108275}\n",
            "I0315 01:38:04.196047 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00090906903,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.000680628,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.087792814,\n",
            " 'Loss/RPNLoss/localization_loss': 0.0001680642,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014259342,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.089693174,\n",
            " 'learning_rate': 0.00042108275}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.583s\n",
            "I0315 01:39:02.480775 140483420235648 model_lib_v2.py:707] Step 4400 per-step time 0.583s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00094664935,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0004218855,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10003005,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00016069073,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014467567,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10170396,\n",
            " 'learning_rate': 0.00031084087}\n",
            "I0315 01:39:02.481116 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00094664935,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0004218855,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.10003005,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00016069073,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014467567,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.10170396,\n",
            " 'learning_rate': 0.00031084087}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.580s\n",
            "I0315 01:40:00.489245 140483420235648 model_lib_v2.py:707] Step 4500 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0003278394,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00033405793,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09316238,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015731192,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00039341455,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094375,\n",
            " 'learning_rate': 0.00021673084}\n",
            "I0315 01:40:00.489607 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0003278394,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00033405793,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09316238,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015731192,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00039341455,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.094375,\n",
            " 'learning_rate': 0.00021673084}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.582s\n",
            "I0315 01:40:58.664029 140483420235648 model_lib_v2.py:707] Step 4600 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.001008912,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00056283746,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.092809334,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00016248044,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014393713,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09468751,\n",
            " 'learning_rate': 0.00013916421}\n",
            "I0315 01:40:58.664367 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.001008912,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.00056283746,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.092809334,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00016248044,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014393713,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09468751,\n",
            " 'learning_rate': 0.00013916421}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.582s\n",
            "I0315 01:41:56.850394 140483420235648 model_lib_v2.py:707] Step 4700 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00069641386,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0006543825,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.092732824,\n",
            " 'Loss/RPNLoss/localization_loss': 0.000112047834,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00038865535,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09458432,\n",
            " 'learning_rate': 7.848001e-05}\n",
            "I0315 01:41:56.850735 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00069641386,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0006543825,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.092732824,\n",
            " 'Loss/RPNLoss/localization_loss': 0.000112047834,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00038865535,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.09458432,\n",
            " 'learning_rate': 7.848001e-05}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.580s\n",
            "I0315 01:42:54.884666 140483420235648 model_lib_v2.py:707] Step 4800 per-step time 0.580s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0010829654,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 4.064373e-05,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.041656464,\n",
            " 'Loss/RPNLoss/localization_loss': 1.0042454e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00024932204,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.04303944,\n",
            " 'learning_rate': 3.4943583e-05}\n",
            "I0315 01:42:54.885020 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0010829654,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 4.064373e-05,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.041656464,\n",
            " 'Loss/RPNLoss/localization_loss': 1.0042454e-05,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00024932204,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.04303944,\n",
            " 'learning_rate': 3.4943583e-05}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.582s\n",
            "I0315 01:43:53.109061 140483420235648 model_lib_v2.py:707] Step 4900 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.0015187565,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 4.0385636e-05,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.042697255,\n",
            " 'Loss/RPNLoss/localization_loss': 9.903804e-06,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00019618015,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.044462483,\n",
            " 'learning_rate': 8.745433e-06}\n",
            "I0315 01:43:53.109477 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.0015187565,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 4.0385636e-05,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.042697255,\n",
            " 'Loss/RPNLoss/localization_loss': 9.903804e-06,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00019618015,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.044462483,\n",
            " 'learning_rate': 8.745433e-06}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.582s\n",
            "I0315 01:44:51.346340 140483420235648 model_lib_v2.py:707] Step 5000 per-step time 0.582s\n",
            "INFO:tensorflow:{'Loss/BoxClassifierLoss/classification_loss': 0.00072828104,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0005766047,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09738344,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015500143,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014366965,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.098987,\n",
            " 'learning_rate': 0.0}\n",
            "I0315 01:44:51.346688 140483420235648 model_lib_v2.py:708] {'Loss/BoxClassifierLoss/classification_loss': 0.00072828104,\n",
            " 'Loss/BoxClassifierLoss/localization_loss': 0.0005766047,\n",
            " 'Loss/BoxClassifierLoss/mask_loss': 0.09738344,\n",
            " 'Loss/RPNLoss/localization_loss': 0.00015500143,\n",
            " 'Loss/RPNLoss/objectness_loss': 0.00014366965,\n",
            " 'Loss/regularization_loss': 0.0,\n",
            " 'Loss/total_loss': 0.098987,\n",
            " 'learning_rate': 0.0}\n"
          ]
        }
      ],
      "source": [
        "!make train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FAQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwGrSK7P3YtD"
      },
      "source": [
        "```\n",
        "ImportError: cannot import name '_registerMatType' from 'cv2.cv2'\n",
        "```\n",
        "\n",
        "> https://stackoverflow.com/questions/70537488/cannot-import-name-registermattype-from-cv2-cv2\n",
        "\n",
        "Execute the following scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkC-TJOp3MBs",
        "outputId": "ea34ed88-50bb-44ee-b552-fbccc04f6c72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opencv-python-headless        4.5.5.64\n",
            "Found existing installation: opencv-python-headless 4.5.5.64\n",
            "Uninstalling opencv-python-headless-4.5.5.64:\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep opencv-python-headless\n",
        "!pip uninstall --yes opencv-python-headless\n",
        "!pip install opencv-python-headless==4.1.2.30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "2 root error(s) found.\n",
        "  (0) UNIMPLEMENTED:  DNN library is not found.\n",
        "     [[{{node functional_1/conv1_conv/Conv2D}}]]\n",
        "     [[StatefulPartitionedCall/SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Reshape_5/_126]]\n",
        "  (1) UNIMPLEMENTED:  DNN library is not found.\n",
        "     [[{{node functional_1/conv1_conv/Conv2D}}]]\n",
        "0 successful operations.\n",
        "```\n",
        "> https://stackoverflow.com/questions/71000120/colab-0-unimplemented-dnn-library-is-not-found\n",
        "\n",
        "Execute the following scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade tf-models-official==2.8.0\n",
        "!pip install --upgrade tensorflow==2.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBMyDvhr9jYE"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh5m4kuo2ffV",
        "outputId": "bf5ff438-4433-4688-b7bc-b2e84289be2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python exporter_main_v2.py \\\n",
            "--input_type image_tensor \\\n",
            "--pipeline_config_path models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config \\\n",
            "--trained_checkpoint_dir models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/ \\\n",
            "--output_directory exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8\n",
            "2022-03-15 01:50:51.997479: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0315 01:50:52.151746 140231422580608 deprecation.py:615] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 01:51:05.413966 140231422580608 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0315 01:51:11.636925 140231422580608 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0315 01:51:12.370753 140231422580608 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0315 01:51:16.064001 140231422580608 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
            "I0315 01:51:17.090064 140231422580608 api.py:459] Removing rpn_box_predictor_features from prediction_dict\n",
            "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
            "I0315 01:51:17.090448 140231422580608 api.py:459] Removing rpn_features_to_crop from prediction_dict\n",
            "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
            "I0315 01:51:17.090646 140231422580608 api.py:459] Removing feature_maps from prediction_dict\n",
            "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
            "I0315 01:51:21.860526 140231422580608 api.py:459] Removing rpn_box_predictor_features from prediction_dict\n",
            "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
            "I0315 01:51:21.860815 140231422580608 api.py:459] Removing rpn_features_to_crop from prediction_dict\n",
            "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
            "I0315 01:51:21.860991 140231422580608 api.py:459] Removing feature_maps from prediction_dict\n",
            "2022-03-15 01:51:24.390246: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "INFO:tensorflow:Removing rpn_box_predictor_features from prediction_dict\n",
            "I0315 01:51:29.345637 140231422580608 api.py:459] Removing rpn_box_predictor_features from prediction_dict\n",
            "INFO:tensorflow:Removing rpn_features_to_crop from prediction_dict\n",
            "I0315 01:51:29.345942 140231422580608 api.py:459] Removing rpn_features_to_crop from prediction_dict\n",
            "INFO:tensorflow:Removing feature_maps from prediction_dict\n",
            "I0315 01:51:29.346111 140231422580608 api.py:459] Removing feature_maps from prediction_dict\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f899bcfe790>, because it is not built.\n",
            "W0315 01:51:29.866027 140231422580608 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x7f899bcfe790>, because it is not built.\n",
            "W0315 01:52:23.625393 140231422580608 save.py:265] Found untraced functions such as FirstStageBoxPredictor_layer_call_fn, FirstStageBoxPredictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, mask_rcnn_box_head_layer_call_fn while saving (showing 5 of 50). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets\n",
            "I0315 01:52:39.829448 140231422580608 builder_impl.py:780] Assets written to: exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "I0315 01:52:41.581831 140231422580608 config_util.py:254] Writing pipeline config file to exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "2022-03-15 01:52:50.059140: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Loading model...Done! Took 29.706755876541138 seconds\n",
            "Running inference for ./images/test/test.jpg... Running inference for ./images/test/15.jpg... Running inference for ./images/test/test_annotated.jpg... Running inference for ./images/test/16.jpg... Done!\n",
            "Annotated images is at ./images/test_annotated/\n"
          ]
        }
      ],
      "source": [
        "!make export && python test_images.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsecweWKSMLX"
      },
      "source": [
        "## Download models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "nG99Poh8AzOB",
        "outputId": "605100a3-db63-407c-a27c-e7ea22ee0a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config (deflated 70%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index (deflated 81%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/checkpoint (deflated 41%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.index (deflated 81%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets/ (stored 0%)\n",
            "  adding: content/object-detection-api/workspace/test-mask/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/saved_model.pb (deflated 92%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_940d0d0f-a6b3-4086-acb9-caebe0a21cf2\", \"exported-modles.zip\", 446509184)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/exported-modles.zip /content/object-detection-api/workspace/test-mask/exported-models\n",
        "files.download(\"/content/exported-modles.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Mask_R_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
